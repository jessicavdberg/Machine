---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Predicting Poverty levels in South Africa"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Jessica van der Berg "  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Stellenbosch University, South Africa" # First Author's Affiliation
Email1: "20190565\\@sun.ac.za" # First Author's Email address


CorrespAuthor_1: FALSE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
  Abstract to be written here. The abstract should not be too long and should provide the reader with a good understanding what you are writing about. Academic papers are not like novels where you keep the reader in suspense. To be effective in getting others to read your paper, be as open and concise about your findings here as possible. Ideally, upon reading your abstract, the reader should feel he / she must read your paper in entirety.
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
library(caTools)
library(dplyr)
library(gridExtra)
library(kableExtra)
library(tidyverse)
library(caret)
library(grid)
library(lares)
library(rpart)
library(rpart.plot)
library(e1071)
library(parallel)
library(vip)

house <- read.csv("C:/Users/jesic/OneDrive/Desktop/ghs-2018-house-1.0-csv.csv")
house.simple <-  select(house, head_popgrp, head_sex, head_age, Q55Bedr, Q55TotRm, Q57Rent, Q58Val, Q63NrCell, Q814Exp, Q89aGrant, Q821WashM, hholdsz, chld17yr_hh, Q42Msal_hh, totmhinc, econact_hh)

#add column. We are making the pp person income using the total monthly income and minus the child17 years an
house.simple$adults <- house.simple$hholdsz - house.simple$chld17yr_hh
house.simple$income_pp <- house.simple$totmhinc / house.simple$adults

# getting rid of all NA and households that did not answer certain questions or who ticked unsure. 
house.simple <- filter(house.simple, Q55Bedr < 99, Q55TotRm < 25, Q814Exp < 11, hholdsz < 15, Q58Val < 9, Q63NrCell < 11, income_pp < 50000, Q821WashM <9)

## Add column
# We will define a household under these
# 1 - extreme poverty - Food poverty line ( <=547)
# 2 - moderate poverty - lower poverty line (<=785)
# 3 - vulnerable - upper bound poverty line (<= 1183)
# 4 - non-vulnerable - the rest of the people (rest)

house.simple$poverty_level <- ifelse(house.simple$income_pp <= 547, 1, ifelse(house.simple$income_pp > 547 & house.simple$income_pp <=785,2,ifelse(house.simple$income_pp > 785 & house.simple$income_pp <=1183,3,4)))

## Need to split data into testing and training data
# here randomly selects 70 % of the rows from the dataset
# 70% is split into the training one, where 30% of same is in the test dataset

##SET SEED HERE 
set.seed(555)
dt <- sort(sample(nrow(house.simple), nrow(house.simple)*.7))
train <- house.simple[dt,]
test <- house.simple[-dt,]


```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}

Since apartheid ended in 1994, the South African Government has committed a significant number of resources to distribute grants effectively and efficiently to the poor and the vulnerable. However, South Africa has remained a country with extremely high levels of inequality and poverty for an upper middle-income country @stats2011social. Previous literature has shown that poverty levels are higher in rural areas than in urban areas. This is largely due to rural household not having access to the same employment opportunities has urban households. South Africa is a country with high levels of unemployment and extremely low wages. This implies that individuals that are economically active can still fall below the upper or lower bound poverty line due to the low wages that they receive @leibbrandt2010trends. 

Poverty remains unacceptably high for a country of South Africa’s economic status and remains closely associated with race.  Thus, poverty reduction remains one of the key economic goals. Poverty in money terms has declined markedly since apartheid ended in 1994. This was made possible by the expansion of the social grant system. However, accurately targeting social welfare programs can be challenging given that income data is often incorrect @vanderberg2017. To overcome this problem, households are subject to a proxy means test (PMT) to identify whether a household qualifies for social assistant.  This essay will try to identify new methods to identify households that are below the food poverty line, lower-bound poverty line and upper bound poverty line using machine learning techniques. 

Structure … `

# Literature Review 

Write a short literature review here on the background of SOuth Africa - max one page 

# Data 

The data used for predicting poverty level was exacted from the General Household Survey (GHS) 2018, which is a survey completed annually by Statistics SA to measure the living circumstances of households in South Africa. They survey includes household and individual characteristics. After taking out all of the NA values and taking out households who did not know or answer the relevant questions, the dataset consists of 14 546 entries. 

Since the GHS consist of household survey, total income per household is reported. To calculate the average monthly income per individual within each household, I first need to calculate the total number of adults within each household. This is done by taking the difference between household size and the number of children under the age of 17. I then take the total monthly income and divide it by the total number of adults to get the average monthly income per individual in each household. This income information is then used to divided the data into four groups. 

The first group is individuals whose income fall below the food poverty line. In 2018, the food poverty line was R547 per month. The food poverty line is also referred to as the extreme poverty line as it refers to the absolute minimum amount an individual will need to be able to afford the minimum energy intake for survival. The second group consist of individuals whose monthly income falls between the food poverty line and the lower-bound poverty line (R785). The lower bound poverty line is the sum of the food poverty line and and minimum amount for non-food items. The third group consist of individuals between the lower-bound poverty line and the upper-bound poverty line (R1183). The final group consist of individuals whose monthly income is above the upper-bound poverty line, which I refer to as non-vulnerable individuals.  Figure 1 graphically displays the process described above in the format of a decision tree, where 1 represents the food poverty line, 2 the lower-bound poverty line, 3 the upper-bound poverty line and 4 the non-vulnerable. 


```{r Figure1,  warning =  FALSE, fig.align = 'center', fig.cap = "Decision tree for poverty levels \\label{Figure1}", fig.ext = 'png', fig.height = 3, fig.width = 6}

fit <- rpart(poverty_level~., data = house.simple, method = 'class')
rpart.plot(fit, extra = 106)
  
```

After all data cleaning was done, 73 percent of households were non-vulnerable, 11 percent were between the upper and lower-bound poverty line, 6 percent between the lower and food poverty line, and 9 percent fell below the food poverty line. To evaluate the performance for the machine learning techniques that I will implement, I randomly split the data into two subsets using a 70:30 ratio. The training dataset will consist of 70 percent of the original dataset, while the test dataset will consist of the remaining 30 percent. Figure 2 below shows the number of household per poverty level for the training dataset. 


\begin{figure}
\centerline{\includegraphics[scale=0.65]{plot1.png}}
\caption{Number of household per poverty level}
\end{figure}

```{r}

plot1 <- train %>%
    ggplot(aes(as.numeric(poverty_level))) +
    geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat = "count", show.legend = TRUE) +
    geom_text(aes(label = scales::percent(..prop..), y = ..prop..), stat = "count", vjust = -.5, size = 3) +
    scale_y_continuous(labels = scales::percent) +
    labs(title = "Poverty levels ", subtitle= " Number of household below a given poverty level", caption = "Own calculations using training dataset") +
    ggthemes::theme_economist_white()+
    theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.title.x = element_blank()) +
    scale_fill_viridis_d(name="Poverty levels:",
                         breaks=c("1", "2", "3", "4"),
                         labels=c("1 = Food poverty line", "2 = Lower bound poverty line", "3 = Upper bound poverty line", "4 = non-poor"))



```
Figure 2 shows that in our training dataset, 73.5 percent of households are non-vulnerable and 9.6 percent of households monthly income falls below the food poverty line. This implies that I have an extremely imbalanced dataset. This is important as it will have an effect on the machine learning techniques that I implement later on. 

For some descriptive statistics, I analyze some of the variable in more details. From the density plots in figure 3.3, I can see that households whose average income per person falls below the upper-bound poverty line (green line) tend to have slightly older head of household (head_age) then those household belonging to other poverty levels. 

A household size (hholdsz) of 1-2 individuals tend have a larger probability to be non-vulnerable (yellow line), where larger household size of 3-5 individuals then have a larger probability of falling below the food poverty line. 

Total expenditure (Q814Exp) is higher for the non-vulnerable households, which makes sense as they receive a higher income. 

The total number of rooms (Q55TotRm) seem to be distributed similarly, with non-vulnerable households having a slightly smaller distribution. This comes as no suprise as these non-vulnerable households tend to have a smaller household size, implying that they need less bedrooms. 

Non-vulnerable household also have much larger property valuation (Q58Val), which could imply that they have a higher standard of living. 

```{r Figure3,  warning =  FALSE, fig.align = 'center', fig.cap = "Distribution of certain variables by poverty level \\label{Figure3}", fig.ext = 'png', fig.height = 3, fig.width = 6}
plot_target_by_var <- function(df, variable){
    var <- enquo(variable)
    df %>%
        ggplot(aes(!!var, fill = as.factor(poverty_level), color = as.factor(poverty_level))) +
        geom_density(alpha = 0.1, size = 1, show.legend = FALSE) +
        scale_colour_viridis_d() +
        theme_minimal()
}


p_age <- plot_target_by_var(train, head_age)
p_size <- plot_target_by_var(train, hholdsz)
p_hhexp <- plot_target_by_var(train, Q814Exp)
p_cellphone <- plot_target_by_var(train, Q63NrCell)
p_room <- plot_target_by_var(train, Q55TotRm)
p_val <- plot_target_by_var(train, Q58Val)
#display plots in a grid
grid.arrange(p_age, p_size, p_hhexp, p_cellphone, p_room , p_val, nrow = 2, top = textGrob("Distribution by poverty levels", gp=gpar(fontsize=15)))

```

Before we start building models we can also analysis which variables are correlated with our dependent variable (which is is poverty level). Figure 3.4 displays the top 10 variables that are correlated with the dependent variable. Our top four that are positively correlated are \textit{econact hh}, which is a binary variable indicating whether or not the household is economically active, \emph{Q814Exp}, which is a numeric variable display total household expenditure, \emph{totmhinc}, which is a numeric variable displaying total household income, and \emph{Q89aGrant}, which is a binary variable indicating whether the household receives a grant or not. 

variables that are negatively correlated with the dependent variable is the sex of the head of the household (\emph{head sex}), whether or not the household owns a washing machine (\emph{Q821WashM}), the household size (\emph{hholdsz}), the amount spent on rent or mortgage of property per month (\emph{Q57Rent}) and the number of adults in the household (\emph{adults}). 

```{r Figure4,  warning =  FALSE, fig.align = 'center', fig.cap = "Correlation with dependent variable \\label{Figure4}", fig.ext = 'png', fig.height = 4, fig.width = 5}

a <- train[,-18] # get rid of income_pp
b <- a[,-14] # get rid of monthly salary
corr_var(b, poverty_level, top=10)

```



#  Methodology \label{Meth}

## Analysing Classification Models 

To see which model predicts poverty most accurately and efficiently, I assess the performance of seven supervised classification models using the caret package. The dataset is extremely unbalanced; therefore, the defaults parameter will be Kappa to order to improve the performance of the models. The Kappa metric compares the observed accuracy with the expected accuracy. It also accounts for random chance which implies that it makes the model more accurate that simply using an Accuracy as a metric. The Kappa matric is calculated using the formula;
\[k = \frac{p_0 -p_e}{1-p_e}\]
Where \(p_0\) represents the overall accuracy of the model and \(p_e\) represents that measure of the agreement between the predictions and actual class value of the model. Therefore, Kappa attempts to account for evaluation bias by considering the correct classification by a random guess @dalpiaz. 

The table below briefly discusses the seven different classification models that I compared to determine which model is the most accurate to predict poverty @boehmke2019hands.


\begin{center}
\begin{tabular}{| m{10em} | m{2cm}| m{10cm} |}
\hline
\textbf{Model} & \textbf{Reference Name} & \textbf{Description} \\
\hline
Multinomial Logistic Regression &  multinom & Makes use of the maximum likelihood estimation to evaluate the probability of a categorical relationship \\
\hline
Linear Discriminant Analysis & lda & Used to find linear combinations of separates multiple classes of features, representing the dependent variable as a linear combination of other features \\
\hline
Naive Bayes & naive bayes & Using Bayes Theorem, this model applies posterior probability to the categorization, making the uneducated assumption that the predictors are independent \\
\hline
Linear Support Vector Machine & svmLinear & The model creates a line that separates data into classes \\
\hline
K-Nearest Neighbor & knn & Each observation in the dataset is predicted based on its similarity to other observations \\
\hline
Recursive Partitioning & rpart & Builds models using a general structure which consist of a two-stage procedure and then final presenting the model as a binary tree \\
\hline 
Ranger & ranger & An updated and fast implementation of random forest for big data \\
\hline
\end{tabular}
\end{center}

### Evaluation 

To ensure that the correct model is chosen, the accuracy of each model is evaluated and compared. However, since the dataset is unbalance, I also analyze the F measure, also known as the \(F_1\) score, of each model. The \(F_1\) score communicates the average between the precision and the recall of each model. A perfect model has an \(F_1\) score equal to 1, therefore models with a higher \(F_1\) score is preferred over models with a lower \(F_1\) score. The formula for the \(F_1\) score is given below;
\[F_1 = 2\times \frac{ precision \times recall}{precision + recall}\]

The extremely unbalanced data will affect the results of the \(F_1\) score. Therefore, it is also informative to evaluate the macro \(F_1\) score and the weighted \(F_1\) score. The macro \(F_1\)  is not affected by unbalanced data and is equal to the average of the \(F_1\) score and is commonly used when there are multiple levels or classes. It gives the same importance to each poverty level. A higher macro \(F_1\) score is preferred to a lower one.  The formula for the macro \(F_1\) score if given below; 
\[ Macro\: F_1\: score = \frac{1}{N}{\sum}_{i=0}^N F_1\]

Where \(N\) is the number of different poverty levels and \(i\) is the levels index. The drawback of the macro \(F_1\) measure is that is gives equal weight to all poverty levels, which implies that it over emphasis the under-represented poverty levels. The weighted average \(F_1\) score is similar to the macro \(F_1\) score, but here the \(F_1\) score is weighed according of the number of households from the specific poverty level, which emphasis poverty levels according to size of each poverty level.  The formula for the weighted \(F_1\) score is given below;
\[ Weighted\: F_1\: score = \frac{n_i\sum_{i=1}^k F_1}{\sum_{i=n}^k n_i}\]

## Decision Tree 
As I will show in section 5.1, decision trees have the fastest computational time without having to compromise much on the accuracy of a model. Decision trees are constructed through an algorithmic approach that identifies the most optimal way to split a dataset based on the information in the dataset. Decision trees are displayed in a flowchart-like structure where each internal node represents some sort of test on a specific feature. Each leaf node then represents a poverty level. The path from the root (the first node) to the leaf represents the classification rules. Decision trees are relatively easy to interpret and therefore, are commonly used @boehmke2019hands. 

## Random Forest 
In section 5.1, I also show that random forest provides perfect accuracy out of all the classification models that are considered, however, it also has the longest computational time. Random forest uses multiple decision trees to provide more flexibility and better accuracy, while reaching a single result. Random forest searches for the best feature form a random subset of features which leads to it providing more randomness to the model. The increased in randomness is what improves the model accuracy as it ensures a low correlation among the multiple decision trees @breiman2015random.  


# Results and Discussion 

## Classification Models 

The table below shows the different metrics to make comparing different models easier. The first feature that is observed is that the models vary drastically in time. The \emph{lda}, \emph{rpart} and \emph{naive bayes} models are extremely fast whereas \emph{multinom} and \emph{ranger} take relatively long to run. Furthermore, \emph{ranger} scores the best for accuracy and \(F_1\) measures. 

```{r}
train$poverty_level <- as.factor(train$poverty_level)
test$poverty_level <- as.factor(test$poverty_level)
# define models to try
models <- c("multinom", "lda", "naive_bayes", "svmLinear", "knn", "rpart", "ranger")
# set CV control for knn, k-folds
control <- trainControl(method = "cv", number = 10, p = .9) # 10 fold, 10%
# fit models
set.seed(1)

quiet(train_models <- lapply(models, function(model){
        print(model)
    train(poverty_level ~ ., method = model, data = train, trControl = control, metric = "Kappa")
}))

names(train_models) <- models


# extract elapsed training times
elapsed <- sapply(train_models, function(object)
    object$times$everything["elapsed"])

# extracting the accuracy from CM in one step without creating a separate predictions vector
acc = sapply(train_models, function(x){
    pred = predict(x, newdata = test)
    cm = confusionMatrix(pred, reference = test$poverty_level)
    return(cm[["overall"]]["Accuracy"])
}
)
# extract F1 by class
F1 = sapply(train_models, function(x){
    pred = predict(x, newdata = test)
    cm = confusionMatrix(pred, reference = test$poverty_level)
    return(cm[["byClass"]][ , "F1"])
}
)
# extract macro F1
F1_M = sapply(train_models, function(x){
    pred = predict(x, newdata = test)
    cm = confusionMatrix(pred, reference = test$poverty_level)
    return(mean(cm[["byClass"]][ , "F1"], na.rm = TRUE))
}
)
# extract weighted F1
F1_W <- sapply(train_models, function(x){
    pred = predict(x, newdata = test)
    cm = confusionMatrix(pred, reference = test$poverty_level)
    actual = colSums(cm$table)
    F1 = cm[["byClass"]][ , "F1"]
    return((sum(actual*F1, na.rm = TRUE))/(sum(actual)))
}
)

df <- data.frame(models, elapsed, acc, F1_M, F1_W)
```


\begin{center}
\begin{tabular}{| c| c| c |c| c|}
\hline
\textbf{Models} & \textbf{Time} & \textbf{Accuracy} & \textbf{Macro \(F_1\)} & \textbf{weighted \(F_1\)} \\
\hline
multinom & 37.17 & 0.9935839 & 0.9820473 & 0.9935798 \\
\hline
lda & 0.81 & 0.7774977 & 0.4561088 & 0.7409658 \\
\hline
naive bayes & 1.67 & 0.8819890 & 0.8138291 & 0.8862441 \\
\hline
svmLinear & 9.91 & 0.9660862 & 0.9134729 & 0.9661192 \\
\hline
knn & 4.81 & 0.9869386 & 0.9714937 & 0.9876236 \\
\hline 
rpart & 1.08 & 0.9372136 & 0.9155884 & 0.9137702 \\
\hline 
ranger & 41.92 & 1.00000000 & 1.00000000 & 1.00000000 \\
\hline
\end{tabular}
\end{center}

Analyzing the accuracy score, Figure 5.1 shows that \emph{ranger} has the highest accuracy, followed closely by \emph{multinom}. However, these two models also take the longest to run. \emph{knn} and \emph{rpart} are relatively fast and they have a high level of accuracy.  For the fastest running models, decision trees (\emph{rpart}) are the most accurate. Figure 5.1 also implies that there is some trade-off between accuracy and computational time.  
```{r Figure5,  warning =  FALSE, fig.align = 'center', fig.cap = "Speed versus Accuracy \\label{Figure5}", fig.ext = 'png', fig.height = 4, fig.width = 6}
plot2 <- ggplot(data=df) +
    geom_point(mapping = aes(x= elapsed, y = acc, color = models, size = 10)) +
    geom_text(aes(x= elapsed, y = acc, color = models, label = models), hjust =0.4, vjust= -0.8, nudge_x = 0.1) +
    labs(y = "Accuracy", x = "Speed", title = "Comparing Speed and Accuracy of Different Models", subtitle = "using training model", caption = "Own calculations") +
    ggthemes::theme_economist_white() +
    theme(legend.position = "none")
```

\begin{figure}
\centerline{\includegraphics[scale=0.65]{accuracy.png}}
\caption{Speed versus Accuracy}
\end{figure}

```{r Figure6,  warning =  FALSE, fig.align = 'center', fig.cap = "Speed versus Macro F1 Score \\label{Figure6}", fig.ext = 'png', fig.height = 5, fig.width = 7.5}
plot3 <- ggplot(data=df) +
    geom_point(mapping = aes(x= elapsed, y = F1_M, color = models, size = 10)) +
    geom_text(aes(x= elapsed, y = F1_M, color = models, label = models), hjust =0.7, vjust= -0.8, nudge_x = 0.1) +
    labs(y = "Macro F1 Score", x = "Speed", title = "Comparing Speed and the Macro-F1 Score of Different Models", subtitle = "using training model", caption = "Own calculations") +
    ggthemes::theme_economist_white() +
    theme(legend.position = "none")


```
Figure 5.2 shows the relationship between computational time and the Macro \(F_1\) score measure. \emph{ranger} and \emph{multinom} still have the highest degree of accuracy. However, \emph{rpart} has a higher degree of accuracy while maintain the same computational time. \emph{naive bayes} is performing worst in terms of accuracy, while \emph{knn},  \emph{svmLinear} and  \emph{lda} are all performing relatively the same. Here, the same conclusion is reached as with Figure 5.1, that decision trees (\emph{rpart}) is the most accurate when analyzing models with the fastest computational time. 
\begin{figure}
\centerline{\includegraphics[scale=0.65]{macroF1.png}}
\caption{Speed versus Macro F1 }
\end{figure}

```{r}
plot4 <- ggplot(data=df) +
    geom_point(mapping = aes(x= elapsed, y = F1_W, color = models, size = 10)) +
    geom_text(aes(x= elapsed, y = F1_W, color = models, label = models), hjust =0.7, vjust= -0.8, nudge_x = 0.1) +
    labs(y = "Weighted F1 Score", x = "Speed", title = "Compaing Speed and the Weighted-F1 Score of Different Models", subtitle = "using training model", caption = "Own calculations") +
    ggthemes::theme_economist_white() +
    theme(legend.position = "none")
```
Figure 5.3 displays that \emph{naive bayes} preforms slightly better in terms of accuracy when compared to the macro \(F_1\) score whereas the rest of the models preform similarly. This suggest that random forest (\emph{ranger}) is the most accurate when predicting poverty across all the measures, however, the computational time is extensive. If you are willing to compromise on the accuracy of a model, then decision tree (\emph{rpart}) is the best model, which serves a high degree of accuracy and an extremely fast computational time. Now that I have determined which models are the best to predict poverty, decisions tree and random forest will be analyzed. 
\begin{figure}
\centerline{\includegraphics[scale=0.65]{weightedF1.png}}
\caption{Speed versus Weighted F1 }
\end{figure}

## Decision Tree 
The decision tree in Figure 5.4 shows the path of classification rules that determine under which poverty level a household is classified, where red (1) represents household falling beneath the food poverty line, orange (2) represents households that are above the food poverty line but below the lower-bound poverty line, purple (3) represents households that are above the lower-bound poverty line but below the upper-bound poverty line and green (4) represents households that are above the upper-bound poverty line. 

As we can see, household income (\emph{totmhinc}), the number of adults in the household (\emph{adults}) and monthly salary (\emph{Q42Msal_hh}) are the only variables used to determine the poverty level of a household. The difference between monthly salary and total household income is that total household income consists of wages/salary, grants and any other type of income a household might receive, whereas monthly salary only consists of money received through employment. Figure 5.4 communicates that income variables and the number of adults are the most important variables when determining the poverty level under which households fall. 

```{r Figure7,  warning =  FALSE, fig.align = 'center', fig.cap = "Decision Tree\\label{Figure7}", fig.ext = 'png', fig.height = 5.5, fig.width = 6}
fit1 <- rpart(poverty_level~.-income_pp, data = train, method = 'class')
rpart.plot(fit1, extra = 106)
```
If a household’s total monthly income is below R2 375, then there is only a 7 percent chance that the household will earn enough to be above the upper-bound poverty line, and this is only for households that consist of only one adult. Therefore, a single adult can earn between R 1190 and R2375 and still be above the upper-bound poverty line. Households of more than 4 adults tend to be poorer than smaller households. This statement supports the findings of @ lanjouw1995poverty that larger households are more likely to be poorer in developing countries. To further assess which variables, determine under which poverty level a household falls, I construct a decision tree not considering any income variables. This is displayed below in Figure 5.5. 

```{r  Figure8,  warning =  FALSE, fig.align = 'center', fig.cap = "Decision Tree excluding income variables\\label{Figure8}", fig.ext = 'png', fig.height = 5.5, fig.width = 6}
fit2 <- rpart(poverty_level~., data = train[,-c(14,15,17,18)], method = 'class')
rpart.plot(fit2, extra = 106)
```
Now that income variables are excluded, a different picture of variables affecting poverty levels are displayed. The first thing we noticed is that all households are economically active are above the upper-bound poverty level. This means the employment is a big determinant of the poverty level a household falls under and that creating more jobs can help reduce poverty. 

Furthermore, households that have a head of younger than 60 years of age, tend to be better off than households where the head is older than 60 years. This implies that old age grants, such as pension grants, could be very important source of income to poorer households. Pension grants provide a regular income to poor households, meaning that it has the potential to reduce poverty. @duflo2003 found that pension grants also have a positive effect on the nutrition and health of young girls. Therefore, pension grants can reduce poverty as well as improve the health on children. It also seems that poorer households receive more than two grants, however, the grants fail to keep the household above the food-poverty line. 

<!-- Make title of bibliography here: -->
<!-- \newpage -->

\newpage

# References {-}

<div id="refs"></div>


# Appendix {-}

## Appendix A {-}

Some appendix information here

## Appendix B {-}

